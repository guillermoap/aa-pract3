{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Clasificación con árboles de decisión\n",
    "\n",
    "### Grupo 6:\n",
    "     - Guillermo Aguirre  C.I. 4817028-5\n",
    "     - Bruno González C.I. 4815697-6\n",
    "     - Mauricio Irace C.I. 4924714-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta tarea es construir clasificadores para conjuntos de datos determinados. \n",
    "\n",
    "Uno de los principales tipos de problemas en los que se utiliza el aprendizaje automático es en los problemas de clasificación. La clasificación puede servir de ayuda a la hora de tomar decisiones además de llevar a cabo tareas que de forma humana serían imposibles de realizar. Por ejemplo, si queremos clasificar conjuntos de objetos que tienen muchos atributos es prácticamente imposible que una persona lo haga eficientemente. \n",
    "\n",
    "A partir de un conjunto de datos con características (atributos) instanciadas y previamente etiquetados se desea entrenar algoritmos para poder clasificar instancias que aún no tienen etiqueta, es decir, no conocemos a qué clase pertenecen. En este sentido se utilizará el algoritmo ID3 extendido para soportar atributos numéricos y retornar no sólo valores binarios. \n",
    "\n",
    "Además, se intenta mejorar la clasificación obtenida a partir de ID3 utilizándolo en conjunto con un mecanismo de votación, del estilo de hard voting. Se genera un árbol para cada clase que retorna si la instancia pertenece a dicha clase o no y en caso de que varios retornen una respuesta positiva se utiliza un algoritmo para desempatar.  \n",
    "\n",
    "Por último se procederá a comparar los algoritmos obtenidos sobre un gran conjunto de datos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parte a - ID3 extendido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "Se implementó el algoritmo ID3 con soporte para atributos numéricos y categóricos, además se retorna el nombre de clase, no sólo valores binarios como se especifica en la definición inicial de ID3. El algoritmo recibe como parámetro para el entrenamiento una lista con los nombres de los atributos numéricos, el resto, se asume son categorías. \n",
    "\n",
    "Para realizar la clasificación el algoritmo ID3 construye un árbol de decisión. \n",
    "\n",
    "\n",
    "### 2.1 Atributos numéricos\n",
    "Para el manejo de atributos numéricos, se tomó como inspiración el método utilizado en C4.5, que consiste en particionar los distintos valores numéricos en dos categorías: por un lado, los menores o iguales a un valor umbral t, y por otro los mayores.  \n",
    "\n",
    "Para efectuar dicha partición, primero se ordenan las filas según el atributo numérico en cuestión, y se recorre ascendentemente. Para cada valor v, se evalúa la ganancia si se eligiera t=v. Se toma finalmente el valor que maximiza la ganancia como umbral.\n",
    "\n",
    "\n",
    "### 2.2 Entrenamiento y pruebas\n",
    "\n",
    "El dataset utilizado en esta parte es Iris, tiene 150 instancias con 4 atributos (numéricos) cada una. Se podría decir que es un dataset pequeño. \n",
    "\n",
    "Tener en cuenta que la medida micro \n",
    "\n",
    "Utilizamos el 80% del dataset para entrenar (elegido aleatoriamente) y el resto para probar y obtuvimos los siguientes resultados:\n",
    "\n",
    "#### Corrida 1:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.8666666666666667 | 0.8666666666666667 | 0.8666666666666667 |\n",
    "| macro | 0.9047619047619048 | 0.8333333333333334 | 0.8333333333333334 |\n",
    "\n",
    "#### Corrida 2:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.9 | 0.9 | 0.9 |\n",
    "| macro | 0.9375 | 0.9090909090909092 | 0.9128856624319419 |\n",
    "\n",
    "#### Corrida 3:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.7666666666666667 | 0.7666666666666667 |0.7666666666666667 |\n",
    "| macro | 0.8444444444444444 | 0.8333333333333334 | 0.78743961352657 |\n",
    "\n",
    "#### Corrida 4:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.6666666666666666 | 0.6666666666666666 | 0.6666666666666666 |\n",
    "| macro | 0.6444444444444444 | 0.6363960113960114 | 0.6090909090909092 |\n",
    "\n",
    "#### Corrida 5:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.8333333333333334 | 0.8333333333333334 | 0.8333333333333334 |\n",
    "| macro | 0.9019607843137255 | 0.8148148148148148 | 0.8341954022988506 |\n",
    "\n",
    "En este caso, al ser tan pequeño el dataset, tanto el entrenamiento como las pruebas son prácticamente instantáneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parte b - Votación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el algoritmo de la parte anterior modificado se construyeron 3 árboles (uno para cada clase). Se utilizaron dos aproximaciones a la hora de elegir el dataset utilizado para entrenar el algoritmo en la generación de estos árboles. La primera es utilizar todo el dataset para los 3 clasificadores y, la otra, es seleccionar aleatoriamente las instancias con las que entrenan (los 3 con juegos de datos diferentes), mediante la partición del dataset de entrenamiento en 3 partes con la misma cantidad de instancias. \n",
    "\n",
    "Cada uno de estos árboles retorna ‘True’ si la instancia evaluada pertenece a su clase o ‘False’ en caso contrario. En los casos de empate, es decir, cuando más de uno retorna ‘True’ o más de uno retorna ‘False’ se utiliza un algoritmo para desempatar. \n",
    "\n",
    "Durante la construcción del árbol de decisión de cada clasificador (hay uno por cada clase) se va almacenando cuantas hojas llegan a la clasificación positiva de dicha clase. Luego teniendo estos números, junto con la cantidad total de hojas del árbol, se calcula que porcentaje de ellas terminan en una clasificación positiva; es decir la probabilidad de dicho clasificador de llegar a una clasificación positiva de su clase.\n",
    "Luego se ponen los 3 clasificadores a clasificar el mismo elemento cada vez. Se utiliza una metodología de hard voting para determinar la clasificación final. En caso de ‘empate’, cuando hay más de un clasificador que clasifica el elemento como de su clase, utilizamos las probabilidades de cada clasificador para desempatar. \n",
    "\n",
    "Ejemplificando:\n",
    "\n",
    "| Clasificador | Clasificación | Prob. de clasificar positivamente su clase |\n",
    "|-------|-----------|--------|\n",
    "| Clase A | True | 20% |\n",
    "| Clase B | True | 30% |\n",
    "| Clase C | False | 55% |\n",
    "\n",
    "Aquí los clasificadores de la clase A y la clase B clasificaron el elemento como de su clase, entonces para desempatar tomamos en cuenta las probabilidades de clasificar positivamente su propia clase. Consideramos que el que clasificó correctamente el elemento es el que tiene menos probabilidad de clasificar positivamente su elemento, ya que al ser menor la probabilidad de clasificarlo positivamente, es un evento más raro que este clasificador de positivo y consideramos que esto hace que la clasificación, en este ejemplo la A, sea la clasificación más segura.\n",
    "El caso de desempate cuando todos clasifican negativamente es análogo. Se toma la clasificación del que tenga la probabilidad más baja de clasificar negativamente un elemento de su clase.\n",
    "\n",
    "Es importante tener en cuenta que la partición del dataset de entrenamiento y pruebas se realiza al principio de cada corrida, por lo tanto la parte a y la parte b utilizan las mismas particiones para entrenar y probar en cada una de las corridas. Considerando esta relación observamos que en esta sección se mejora lo obtenido en la sección anterior. \n",
    "\n",
    "Utilizando el 80% del dataset para entrenar los 3 clasificadores se obtuvieron los siguientes resultados: \n",
    "\n",
    "#### Corrida 1:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.9333333333333333 | 0.9333333333333333 | 0.9333333333333333 |\n",
    "| macro | 0.9249999999999999 | 0.9249999999999999 | 0.9249999999999999 |\n",
    "\n",
    "#### Corrida 2:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.8666666666666667 | 0.8666666666666667 | 0.8666666666666667 |\n",
    "| macro | 0.8931623931623932 | 0.8628593628593628 | 0.8749366575453532 |\n",
    "\n",
    "#### Corrida 3:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.7666666666666667 | 0.7666666666666667 |0.7666666666666667 |\n",
    "| macro | 0.8444444444444444 | 0.8333333333333334 | 0.78743961352657 |\n",
    "\n",
    "Observar que en esta corrida (3) el algortimo de la parte a y de la parte b dieron exactamente los mismos valores para todas las métricas y scores. \n",
    "\n",
    "#### Corrida 4:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.7 | 0.7 | 0.7 |\n",
    "| macro | 0.5303030303030303 | 0.6666666666666666 | 0.580952380952381 |\n",
    "\n",
    "#### Corrida 5:\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.9666666666666667 | 0.9666666666666667 | 0.9666666666666667 |\n",
    "| macro | 0.9666666666666667 | 0.9722222222222222 | 0.9679633867276888 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parte c - Comparación a y b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta parte se usó el Cover Type Dataset. Otro clásico Data Set típicamente utilizado como benchmark dado su extensa cantidad de ejemplos, así como de atributos. Para ser concretos, hablamos de 581.012 instancias con 54 atributos cada una.\n",
    "\n",
    "En particular, intentamos una primer corrida con todos los atributos y todos los datos tal cual. La misma tardó 12 horas en completarse, y obtuvimos muy malos resultados (observar  la tabla de ‘corrida inicial’ en la sección 3.2.  La necesidad de mejorar estos tiempos se volvió un factor clave para llegar a buen puerto.\n",
    "\n",
    "### 4.1 Optimizaciones\n",
    "\n",
    "Debido a la ya mencionada extensión, y los problema ocasionados por la misma, tuvimos que buscar estrategias de optimización.\n",
    "\n",
    "### 4.1.1. Teorema de Fayyad-Irani\n",
    "\n",
    "En [Fayyad-Irani](https://www.ijcai.org/Proceedings/93-2/Papers/022.pdf) se plantea un teorema que plantea una técnica de optimización. Básicamente, si todos las clases para un posible umbral son iguales, ese valor no puede generar una ganancia máxima.\n",
    "\n",
    "En concreto en este dataset, el aumento no fue sustancial, eliminando no más de 20 casos dentro del medio millón que había. Finalmente, se optó por eliminar en pos de \n",
    "facilitar la implementación de la próxima optimización.\n",
    "\n",
    "### 4.1.2. Iteración por indices\n",
    "\n",
    "Se notó que el cálculo de cada partición era costoso. Para mejorar esto, se aprovechó el orden para iterar por índice del dataset panda, utilizando los índices con valores únicos.\n",
    "Gracias a esto, en vez de re-filtrar usando un filtro de selección [dataset[atributo]< umbral], solo tomamos los primeros i valores, y luego los siguientes, sin necesidad de un cálculo para la selección.\n",
    "El rendimiento mejoró.\n",
    "\n",
    "### 4.1.3. Eliminación de atributos y datos\n",
    "\n",
    "Por último, se buscó simplificar los dos pares de secuencias de columnas binarias, que según el dataset correspondian 4 a Wilderness Area y 40 a Soil Type.\n",
    "Se probó crear dos campos enteros, utilizando la representación binaria de ambos meta-atributos. Notamos enseguida, tras dicha transformación, que todos los valores generados eran potencia de dos, es decir, solo había un uno en todas las columnas. De esta forma, tomamos Wilderness Area y Soil Type como el número de columna en la que había un uno, pasandolo a los [1..4] y [1..40] respectivamente. Así fue que se redujeron los posibles valores exponencialmente. Por eso eso el dataset lo guardamos como covtype.data.opt.log.csv, donde log denota logaritmo, puesto que redujimos la cantidad de hijos de los nodos de estos atributos de n a log(n). También probamos con sólo los valores categóricos covtype.data.opt.old.csv que no terminó, y los numéricos que consideramos más relevantes covtype.data.opt.csv. Los últimos fueron reducidos con la media del shade segun la hora del día, juntando dicha terna de atributos, \n",
    "\n",
    "Se terminó usando la décima parte del dataset, a pesar de la pérdida que esto implica, pero a favor de evitar un sobreajuste y reducir el tiempo de generación de los árboles.\n",
    "\n",
    "### 4.2. Entrenamiento y pruebas\n",
    "\n",
    "En todos los casos separó el 80% para entrenamiento y el 20% para testeo del subconjunto escogido.\n",
    "\n",
    "Corrida original con el **Dataset completo**\n",
    "\n",
    "**Arbol multiclase:**\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.42459316885106235 | 0.42459316885106235 | 0.42459316885106235 |\n",
    "| macro | 0.23825970619567954 | 0.2798031497827124 | 0.21790686142130025 |\n",
    "\n",
    "**Votación:**\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.4828790995068974 | 0.4828790995068974 | 0.48287909950689734 |\n",
    "| macro | 0.16885041880377868 | 0.21271877528665634 | 0.17839859300579222 |\n",
    "\n",
    "\n",
    "Dataset: **Covtype.data.opt.csv**\n",
    "\n",
    "\n",
    "**Arbol multiclase:**\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.3247863247863248 | 0.3247863247863248 | 0.3247863247863248 |\n",
    "| macro | 0.1198608475648324 | 0.11145833333333333 | 0.1154011154011154 |\n",
    "\n",
    "**Votación:**\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.3162393162393162 | 0.3162393162393162 | 0.3162393162393162 |\n",
    "| macro | 0.11733021077283372 | 0.10885416666666665 | 0.11288888888888889 |\n",
    "\n",
    "\n",
    "Dataset: **Covtype.data.opt.log.csv**\n",
    "\n",
    "**Arbol multiclase:**\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.6068376068376068 | 0.6068376068376068 | 0.6068376068376068 |\n",
    "| macro | 0.6864957264957265 | 0.5956094559035736 | 0.610430601208468 |\n",
    "\n",
    "**Votación:**\n",
    "\n",
    "| score | precision | recall | f1 |\n",
    "|-------|-----------|--------|----|\n",
    "| micro | 0.6068376068376068 | 0.6068376068376068 | 0.6068376068376068 |\n",
    "| macro | 0.6692810457516339 |  0.5743251846193024 | 0.5862278244631186 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este práctico se construyeron dos tipos de clasificadores con distintos resultados. En el caso del Iris dataset, se obtuvieron resultados similares, con ambos clasificadores, aunque en corridas con el mismo conjunto de entrenamiento, se obtuvieron mejores resultados en las 3 medidas tomadas.\n",
    "\n",
    "Por otro lado, vimos que puede no todos los atributos son útiles a la hora de clasificar, y que es necesario un trabajo serio de ingeniería de atributos, no solo para mejorar el rendimiento del clasificador en tiempo de entrenamiento, sino su calidad en tiempo de ejecución. Esto se ve comparando las medidas de Covtype.data.opt.csv, que fueron claramente inferiores a Covtype.data.opt.log.csv. También, viendo el f1-scores, y asumiendo que tanto precision y recall son importantes (recordemos que la medida f-1 es la media armónica de estos dos) podemos decir que de nuevo, se obtuvieron mejores resultados en votación.\n",
    "\n",
    "De todo esto, concluimos que es destacable la importancia de una buena ingeniería de atributos, y de probar distintas técnicas de clasificación para el mismo problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Anexos: Medidas de rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el campo del Aprendizaje Automático, y en particular en la construcción de clasificadores, es necesario utilizar medidas para determinar lo bien que se ha aprendido. A continuación se destacan las medidas que utilizamos para medir los clasificadores construidos:\n",
    "\n",
    "### 6.1. Precisión\n",
    "\n",
    "Proporción de ejemplos realmente positivos dentro del total de ejemplos clasificados como positivos.\n",
    " \n",
    "Precision = Vp / (Vp+Fp)  \n",
    "\n",
    "### 6.2. Recall\n",
    "\n",
    "Proporción de ejemplos positivos que en fueron clasificados como tales. \n",
    "\n",
    "Recall= Vp / (Vp+Fn)  \n",
    "\n",
    "### 6.3. F-1\n",
    "\n",
    "Media armónica de precisión y recall\n",
    "\n",
    "F1 = 2 * (Precision * Recall ) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bibliografía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ID3. Ejemplo de aplicación](https://www.nebrija.es/~cmalagon/inco/apuntes_mios/ejemplo_ID3_clase.pdf)\n",
    "\n",
    "[COMPARATIVA Y ANÁLISIS DE ALGORITMOS DE APRENDIZAJE AUTOMÁTICO PARA LA PREDICCIÓN DEL TIPO PREDOMINANTE DE CUBIERTA ARBÓREA](https://eprints.ucm.es/48800/1/Memoria%20TFM%20Machine%20Learning_Juan_Zamorano_para_difundir%20%282%29.pdf)\n",
    "\n",
    "[Fayyad-Irani](https://www.ijcai.org/Proceedings/93-2/Papers/022.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
